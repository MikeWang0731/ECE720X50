{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Question 2"},{"metadata":{},"cell_type":"markdown","source":"This notebook provides the skeleton for Question 2. Just as with Question 1, you do not need to use this notebook for the assignment, it is only to provide guidance."},{"metadata":{},"cell_type":"markdown","source":"Make the necessary imports to complete this question. You do not need to use these specific imports and may add or remove as you deem necessary. "},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\n\nfrom sklearn.model_selection import KFold\n\nfrom keras.models import Sequential\nfrom keras.layers import LSTM\nfrom keras.layers import Dense","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's start with loading the training dataset."},{"metadata":{"trusted":true},"cell_type":"code","source":"data = pd.read_csv('weather_training.csv', parse_dates=['Date'])\ndata","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The dataset consists of daily minimum temperatures from the beginning of 1981 to the middle of 1990."},{"metadata":{},"cell_type":"markdown","source":"Convert the data to a numpy matrix and extract the temperatures."},{"metadata":{"trusted":true},"cell_type":"code","source":"data_numpy = data.to_numpy()\nX = data_numpy[:,1].astype(float)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Just as in Question 1, it's a good idea to perform exploratory data analysis on the training data. In particular, a line plot charting the temperature as a function of time will be useful."},{"metadata":{"trusted":true},"cell_type":"code","source":"'''TODO: Perform exploratory data analysis on the training data'''","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Based on the results of your exploratory data analysis, apply some preprocessing to the training data or justify in a comment why preprocessing is not necessary."},{"metadata":{"trusted":true},"cell_type":"code","source":"'''TODO: Apply preprocessing to the training data or justify why it's not necessary'''","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"One of the key questions you will have to resolve is how to generate training samples for the neural network. Because the data is temporal, using 10-fold cross-validation at this step is not appropriate since inputs have to precede outputs. On the other hand, splitting the training data by extracting the last 100 days for validation will not capture the diversity of the decade. The correct solution will generate many samples across that span the entire decade. This will allow the network to learn and generalize patterns across seasons."},{"metadata":{"trusted":true},"cell_type":"code","source":"'''TODO: Generate training samples for the neural network'''","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Once you've obtained the training samples, you can build the neural network. It's important that you build it such that its architecture is consistent with how training samples were generated. As in Question 1, you can use the Sequential API, this time with LSTM and Dense layers. Explore various hyperparameters and select the ones which produce the best results."},{"metadata":{"trusted":true},"cell_type":"code","source":"model = Sequential([\n    '''TODO: Design a recurrent neural network using LSTM and Dense layers'''\n])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Once the model has been built, compile it with parameters suitable for time series forecasting."},{"metadata":{"trusted":true},"cell_type":"code","source":"model.compile(\n  '''TODO: Compile the neural netowrk with parameters suitable for time series forecasting'''\n)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Once the model has been compiled, it's ready to train and evaluate. If the samples generation was done correctly, 10-fold cross-validation may be performed at this stage to prevent overfitting of the model."},{"metadata":{"trusted":true},"cell_type":"code","source":"kf = KFold(n_splits=10)\nfor fold_train_idx, fold_val_idx in kf.split('''TODO: Split generated training samples'''):\n    '''TODO: Train and evaluate the model on the current fold'''","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Use the trained model to predict the next 100 days following the last day in the training dataset. Save your predictions as a csv file."},{"metadata":{"trusted":true},"cell_type":"code","source":"model.predict(\n    '''TODO: Predict the next 100 days'''\n)\n'''Save your predictions to csv file'''","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.9","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}